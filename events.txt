Bulk Data received
  - file saved / uploaded somewhere
  - enqueued for processing
Bulk Data processed
  - New processes found
  - Other processes missing
  - New ports open!?!?

Workflows:

User signs in, if they don't have any environments or machines reporting in, we give a great "to get started, add this script to cron."

See currently running processes on a machine, then click on it and get its data.

Would like to search for processes that have run on the machine by name, then click on it and get all of its historical data.
  Historical data:
    Port availability (changes?)
    Graphed time-series
    Time started
    Time ended(?)
    Args

Any given time: list of current processes (upids?)
  hgetall each upid...

List of all processes that have been seen on a machine by args/ucomm (search box to find a process that may not be running any more.)

Bulk Data received
  - file saved / uploaded
  - process thing placed on work queue
  - worker processes tarball
    - tar-xzf to local disk
    - convert to big-ass json doc
    - put on work queue to update datums!
  - worker processes json doc
    - for each thing collected, zadd it appropriately
    - update all attribute hashes gathered
    - diff the process list from current
      - update current process list
      - emit process changes
        - machine/blah/processes : {kind:remove, data:id}

Work Queue
  /queues [set] - list of queue ids, for qpid to check up on

  /jobs/id [hsh] - job details

  /queues/id [hsh] - queue details (acceptable processing time, maybe some stats.)

  /queues/id/pending [list] list of job ids that have not been processed
  /queues/id/processing [list] list of jobs being processed

  worker RPOPLPUSH /queues/id/pending /queues/id/processing, with returned id, set the STARTED_AT column *immediately*
  when the worker finishes, they set /jobs/id:COMPLETED_AT column, LREM /queues/id/processing /jobs/id, del /jobs/id, update /queues/id:LAST_PROCESSED_AT
  
  qpid wakes up, and for each queue in /queues:
    get /queues/id
    check /queues/id:ALERT_ON_SIZE /queues/id/pending size to determine if we need to alert sysadmin
    check each member of /queues/id/processing, and for each member:
      get /jobs/id
        if (missing || (STARTED_AT && COMPLETED_AT)) -> lrem /queues/id/processing /jobs/id (completed but not cleaned case).
        if (STARTED_AT == null)
          add to internal queue with current time to check again in a bit.
        if (current_time > (STARTED_AT + ACCEPTABLE_PROC_TIME))
          incr /jobs/id/TIMEOUTS
          LREM /queues/id/processing /jobs/id
          RPUSH /queues/id/pending /jobs/id
        